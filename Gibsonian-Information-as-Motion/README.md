Comparison of Shannon and Gibsonian Information [link](https://github.com/Orthogonal-Research-Lab/Cybernetics-and-Systems/tree/master/Information%20Theory)

Notes on Gibsonian Information:

1) Disjoint distribution:

* overlapping squares example: given two overlapping squares of identical height and width, what is the phase angle between the corresponding corners?

* adjacent faces example: given two adjacent squares squares of identical height and width, what is their angle of divergence? 

In both of these examples, we encounter a distribution of phase angles. In the first examples, this measures the degree of overlap at each corner. Since these corners are generally flat, these angles are all identical. Their value, however, provides us with a distribution in radians that can be compared against a measure of visual coherence. This visual coherence is demonstrated in anaglyphs and isometric illusions. When the overlapping squares are perceived as a cube, the visual coherence measure is maximized. The relatuion between overlap in radians and visual coherence is known as the Gibsonian Information function.

2) Maximum and Minimum Coherent Movement:

* corresponds to $H_max$ and $H_min$ in Shannon Information.

* changes in the disjoint distribution over time relative to changes in the observer's position. For a viewpoint network, the disjoint distirbution is static.

Mention in BabyMinds paper:

* can we start to develop a quantitative model (Gibsonian Information as the basis for developmental freedom, or learning exploration on a nearly-static neural network).

See Neuromatch slides on [Developmental AI](https://github.com/Orthogonal-Research-Lab/Proposals/blob/master/AI%20as%20an%20Embodied%20Developmental%20Process/Abstract-and-slides.md) 
